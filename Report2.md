# Reproducibility of Papers from Various Scientific Fields

# Introduction

# Methods

# Discussion

## Human Genetics In Disease Identification (Alina Tan)

## Medical Imaging and Segmentation (Megan Ng)

## Iron Deficiency and Blood Donation (Matthew Schinwald)

## Bacterial Genomics in Health Settings (Monica Cella)

##  Neuroplasticity and Perceptual Learning (Ashim Pandey)

## Cortex-wide Brain Imaging and Neural Dynamics (Rian Fritz D. Jalandoni)

## Single Molecule Imaging of DNA Interacting Proteins (Lydia Hodgins)
5 papers related to single molecule tracking and analysis of the dynamics of DNA interacting proteins were evaluated as they relate to the research topic studied by contributor LH. These papers fall into the scientific fields of fundamental biology and biophysics. They range in publication years from 2019 to 2024 and represent the publication journals: Journal of Physical Chemistry, Nucleic Acids Research, Journal of Physics D: Applied Physics, eLife, and Molecular Cell. Overall, it is found that these publications perform well in the description of methods, sample population, and tools categories, but perform poorly in both the data and tool availability categories. When evaluating my personal impression of the reproducibility of these papers I found that data and tool availability had the biggest impact on my decision, resulting in most papers receiving a low score. 

Mine-Hattab et al. (2021) received the highest reproducibility score (4) and was the only paper that scored 3/3 in data availability. This study provided all raw data through a zenodo data base. Both the description of the methods and the sample populations are clear, detailed, and well organized. However, the description of the tools used in this study lacked detail such as microscope and software specifications. The study evaluated poorest in the tool availability category as all analysis programs were custom-built and not openly shared. This observation resulted in an overall reproducibility score of 4/5 as the data is available, however, analysis depends on either cooperation from the authors to share their code or use of another software chosen or developed based on the description of analysis methods. Either of which introduce uncertainty regarding the execution of reproducing the results. 

El Sayyed et al. (2024) received the next highest reproducibility score (3). This study had a very clear and detailed materials and methods section, scoring 3 across the board for description of methods, data and tools. Where this study performs poorly is the availability of both the data and tools. Only a portion of the raw data is openly accessible, which does not include the data which most significantly contributes to the conclusions. However, a statement is provided claiming, “any additional information required to reanalyze the data reported in this paper is available from the lead contact upon request” (El Sayyed et al., 2024). With respect to the tools, links are provided for any open source code and software that was used, but the software used for the core analysis is declared to be custom and is not openly shared. The limited access to both the data and analysis tools is why this paper receives an overall score of 3/5 as it is possible the results could be reproduced but this is highly dependent on the authors complying to the claim that additional data and software will be shared.

Fan et al. (2023) and Bettridge et al. (2023) both received 2/5 for their overall reproducibility scores. For Fan et al. (2023) the study performed well with respect to the description of methods and data but performed poorly when describing the tools as import specifications regarding the microscope were omitted and few to no parameters were provided for both image acquisition and analysis. Additionally, no data or custom code are openly available. Only links to open-source software and a note stating data will be provided upon request are provided. For Bettridge et al. (2023) the study provided clear and detailed descriptions of the methods, data and tools. Again for this study, no data or custom analysis code is openly accessible. No statement is provided regarding the authors’ position on sharing the data, however, it is noted that some custom code is available upon request. The heavy reliance on compliance from the authors’ to share both data and analysis code to reproduce these studies is why both received a overall score of 2/5 as it is uncertain whether compliance would be experienced. 

Lastly, Banaz et al. (2019) received the lowest reproducibility score of 1/5 and performed very poorly across the board. The study lacked a materials and methods section and instead reports poorly detailed methods throughout the main text. Additionally, specific details regarding the population sample, repeats, microscope specifications, and utilized software or code are missing. No data is openly available and no acknowledgement regarding its available is provided. With respect to the software tools, more information is necessary from the authors to identify what tools were used and how to access them.

## Machine learning for biological insights from sequence modelling  (César Miguel Valdez Córdova)

## Biomedical Engineering Methods for drug delivery and microfluidics (Ioan Duchastel)

## Pathophysiological Modelling for Optic Nerve Injury (Ryan Huang)

## Neural Signal Analysis of Anesthesia-Associated Brain Dynamics Change (Ryan Huang)


# Conclusion

# References
